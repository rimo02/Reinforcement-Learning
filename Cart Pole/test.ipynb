{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "states = env.observation_space.shape[0]\n",
    "actions = env.action_space.n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 24)                120       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 24)                600       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 50        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_model(states, actions):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(1, states)))\n",
    "    model.add(Dense(24, activation=\"relu\"))\n",
    "    model.add(Dense(24, activation=\"relu\"))\n",
    "    model.add(Dense(actions, activation=\"linear\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(states, actions)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    policy = BoltzmannQPolicy()\n",
    "    memory = SequentialMemory(limit=50000, window_length=1)\n",
    "    dqn = DQNAgent(model=model, memory=memory,\n",
    "                   nb_actions=actions, policy=policy)\n",
    "    dqn.compile(Adam(learning_rate=1e-3), metrics=['mae'])\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.load_weights('./dqn_weights1.h5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 15 episodes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: reward: 149.000, steps: 149\n",
      "Episode 2: reward: 169.000, steps: 169\n",
      "Episode 3: reward: 150.000, steps: 150\n",
      "Episode 4: reward: 169.000, steps: 169\n",
      "Episode 5: reward: 161.000, steps: 161\n",
      "Episode 6: reward: 160.000, steps: 160\n",
      "Episode 7: reward: 157.000, steps: 157\n",
      "Episode 8: reward: 162.000, steps: 162\n",
      "Episode 9: reward: 164.000, steps: 164\n",
      "Episode 10: reward: 164.000, steps: 164\n",
      "Episode 11: reward: 169.000, steps: 169\n",
      "Episode 12: reward: 161.000, steps: 161\n",
      "Episode 13: reward: 146.000, steps: 146\n",
      "Episode 14: reward: 162.000, steps: 162\n",
      "Episode 15: reward: 167.000, steps: 167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x212ef6e2150>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.test(env, nb_episodes=15, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
